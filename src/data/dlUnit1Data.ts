import { type FlashcardData } from '../components/Flashcard';

export const dlUnit1Data: FlashcardData[] = [
    {
        id: 1,
        title: "1. Introduction to Machine Learning",
        frontText: "What is Machine Learning & Types of Learning?",
        backTitle: "ML Fundamentals",
        importance: "high",
        backContent: [
            "ğŸ¯ ML Definition: Computers learning from data without explicit programming",
            "ğŸ“Š SUPERVISED: Labeled data â†’ Classification (discrete) & Regression (continuous)",
            "ğŸ” UNSUPERVISED: Unlabeled data â†’ Clustering, Dimensionality Reduction",
            "ğŸ® REINFORCEMENT: Agent learns via rewards/penalties in environment",
            "âš¡ AKTU Focus: Differences between supervised, unsupervised, reinforcement learning",
            "ğŸ“ˆ Applications: Image Recognition, NLP, Recommendation Systems, Autonomous Vehicles"
        ]
    },
    {
        id: 2,
        title: "2. Support Vector Machines (SVMs)",
        frontText: "Linear Classification with Maximum Margin",
        backTitle: "SVM Concepts",
        importance: "high",
        backContent: [
            "ğŸ¯ Goal: Find optimal hyperplane that maximizes margin between classes",
            "ğŸ“ Hyperplane Equation: wÂ·x + b = 0 (decision boundary)",
            "ğŸ“ MARGIN: Distance between hyperplane and nearest data points",
            "â­ SUPPORT VECTORS: Data points closest to decision boundary (critical points)",
            "ğŸ”§ KERNEL TRICK: Transform non-linear data to higher dimensions",
            "  â€¢ Linear Kernel: K(x,y) = xÂ·y",
            "  â€¢ RBF/Gaussian: K(x,y) = exp(-Î³||x-y||Â²)",
            "  â€¢ Polynomial: K(x,y) = (xÂ·y + c)^d",
            "âš¡ AKTU Important: Derive margin maximization, kernel functions"
        ]
    },
    {
        id: 3,
        title: "3. Perceptron - The Foundation",
        frontText: "Single Layer Neural Network (1958 - Rosenblatt)",
        backTitle: "Perceptron Details",
        importance: "high",
        backContent: [
            "ğŸ§  PERCEPTRON: Simplest neural network - single artificial neuron",
            "ğŸ“¥ INPUTS: xâ‚, xâ‚‚, ..., xâ‚™ (features)",
            "âš–ï¸ WEIGHTS: wâ‚, wâ‚‚, ..., wâ‚™ (learned parameters)",
            "ğŸ¯ WEIGHTED SUM: z = Î£(wáµ¢xáµ¢) + b (bias)",
            "ğŸ“¤ ACTIVATION: y = step(z) = 1 if z â‰¥ 0, else 0",
            "ğŸ”„ LEARNING RULE: wáµ¢(new) = wáµ¢(old) + Î·(y_true - y_pred)xáµ¢",
            "âš ï¸ LIMITATION: Can only solve LINEARLY SEPARABLE problems",
            "âŒ XOR Problem: Perceptron cannot solve XOR (not linearly separable)",
            "âš¡ AKTU: Very frequently asked - derive learning rule, XOR problem"
        ]
    },
    {
        id: 4,
        title: "4. Logistic Regression",
        frontText: "Probabilistic Binary Classification",
        backTitle: "Logistic Regression",
        importance: "high",
        backContent: [
            "ğŸ¯ Output: Probability P(y=1|x) âˆˆ [0, 1]",
            "ğŸ“ˆ SIGMOID Function: Ïƒ(z) = 1 / (1 + e^(-z))",
            "ğŸ“ Linear Combination: z = wÂ·x + b",
            "ğŸ”® Prediction: P(y=1) = Ïƒ(wÂ·x + b)",
            "ğŸ“‰ CROSS-ENTROPY LOSS: L = -[yÂ·log(Å·) + (1-y)Â·log(1-Å·)]",
            "ğŸ”„ Gradient Descent Update: w = w - Î·Â·âˆ‚L/âˆ‚w",
            "ğŸ†š vs Linear Regression: Classification vs Regression, Sigmoid vs Linear",
            "âš¡ AKTU Focus: Derive sigmoid, cross-entropy loss, gradient updates"
        ]
    },
    {
        id: 5,
        title: "5. Shallow Neural Networks",
        frontText: "What Does a Shallow Network Compute?",
        backTitle: "Shallow Network Architecture",
        importance: "medium",
        backContent: [
            "ğŸ—ï¸ ARCHITECTURE: Input â†’ Hidden Layer â†’ Output",
            "ğŸ“Š Hidden Layer: z = WÂ·x + b, a = g(z) where g is activation",
            "ğŸ”Œ ACTIVATION FUNCTIONS:",
            "  â€¢ Sigmoid: Ïƒ(z) = 1/(1+e^(-z)) â†’ (0,1) - vanishing gradient issue",
            "  â€¢ Tanh: tanh(z) = (e^z - e^(-z))/(e^z + e^(-z)) â†’ (-1,1)",
            "  â€¢ ReLU: max(0, z) â†’ Most used, solves vanishing gradient",
            "  â€¢ Leaky ReLU: max(Î±z, z) where Î± << 1",
            "ğŸ“ UNIVERSAL APPROXIMATION: Even 1 hidden layer can approximate any function",
            "âš ï¸ Limitation: May need exponentially many neurons for complex functions"
        ]
    },
    {
        id: 6,
        title: "6. Loss Functions",
        frontText: "Measuring Model Error",
        backTitle: "Types of Loss Functions",
        importance: "high",
        backContent: [
            "ğŸ¯ PURPOSE: Quantify difference between predictions and actual values",
            "ğŸ“Š REGRESSION LOSSES:",
            "  â€¢ MSE (Mean Squared Error): L = (1/n)Î£(y - Å·)Â²",
            "  â€¢ MAE (Mean Absolute Error): L = (1/n)Î£|y - Å·|",
            "  â€¢ Huber Loss: Combines MSE & MAE (robust to outliers)",
            "ğŸ“ˆ CLASSIFICATION LOSSES:",
            "  â€¢ Binary Cross-Entropy: -[yÂ·log(Å·) + (1-y)Â·log(1-Å·)]",
            "  â€¢ Categorical Cross-Entropy: -Î£yáµ¢Â·log(Å·áµ¢)",
            "  â€¢ Hinge Loss (SVM): max(0, 1 - yÂ·Å·)",
            "âš¡ AKTU: Derive MSE, Cross-entropy, explain when to use each"
        ]
    },
    {
        id: 7,
        title: "7. Backpropagation Algorithm",
        frontText: "How Neural Networks Learn",
        backTitle: "Backpropagation Details",
        importance: "high",
        backContent: [
            "ğŸ¯ PURPOSE: Efficiently compute gradients using chain rule",
            "ğŸ”„ FORWARD PASS: Compute outputs layer by layer",
            "ğŸ“‰ BACKWARD PASS: Compute gradients from output to input",
            "â›“ï¸ CHAIN RULE: âˆ‚L/âˆ‚w = âˆ‚L/âˆ‚a Â· âˆ‚a/âˆ‚z Â· âˆ‚z/âˆ‚w",
            "ğŸ“ ALGORITHM STEPS:",
            "  1. Forward pass: compute all activations",
            "  2. Compute output layer error: Î´ = âˆ‚L/âˆ‚a Â· g'(z)",
            "  3. Backpropagate: Î´Ë¡ = (WË¡âºÂ¹)áµ€Î´Ë¡âºÂ¹ âŠ™ g'(zË¡)",
            "  4. Update: W = W - Î·Â·Î´Â·aáµ€, b = b - Î·Â·Î´",
            "âš¡ AKTU VERY IMPORTANT: Derive backprop for 2-layer network"
        ]
    },
    {
        id: 8,
        title: "8. Stochastic Gradient Descent (SGD)",
        frontText: "Optimization for Large Datasets",
        backTitle: "SGD Variants",
        importance: "high",
        backContent: [
            "ğŸ“Š BATCH GD: Use ALL samples â†’ Slow, stable, memory intensive",
            "âš¡ STOCHASTIC GD: Use 1 sample â†’ Fast, noisy, quick updates",
            "ğŸ¯ MINI-BATCH GD: Use subset (32-256) â†’ Best of both worlds",
            "ğŸ“ˆ LEARNING RATE (Î·): Too high = diverge, Too low = slow convergence",
            "ğŸš€ SGD IMPROVEMENTS:",
            "  â€¢ Momentum: v = Î²v - Î·âˆ‡L, w = w + v (accelerates convergence)",
            "  â€¢ RMSprop: Adaptive learning rate using squared gradients",
            "  â€¢ Adam: Momentum + RMSprop (most popular optimizer)",
            "âš¡ AKTU: Compare Batch GD vs SGD vs Mini-batch, Adam optimizer"
        ]
    },
    {
        id: 9,
        title: "9. Universal Function Approximation",
        frontText: "Neural Networks Can Learn Any Function",
        backTitle: "Universal Approximation Theorem",
        importance: "medium",
        backContent: [
            "ğŸ“œ THEOREM (Cybenko 1989, Hornik 1991):",
            "A feedforward network with a single hidden layer containing finite neurons can approximate any continuous function on compact subsets of Râ¿",
            "âš ï¸ CONDITIONS:",
            "  â€¢ Activation must be non-constant, bounded, continuous (sigmoid)",
            "  â€¢ Or: any non-polynomial activation (ReLU)",
            "ğŸ¯ IMPLICATION: NNs are theoretically powerful enough for any task",
            "âš ï¸ PRACTICAL LIMITATIONS:",
            "  â€¢ May need exponentially many neurons",
            "  â€¢ Doesn't guarantee we can FIND the right weights",
            "  â€¢ Deep networks often more efficient than wide shallow ones",
            "âš¡ AKTU: Explain theorem, limitations, why we use deep networks"
        ]
    }
];
