import { type FlashcardData } from '../components/Flashcard';

export const dwmUnit3Data: FlashcardData[] = [
    {
        id: 1,
        title: "1. Data Mining - Overview",
        frontText: "What is Data Mining?",
        frontImage: "/dwm/kdd_process.png",
        backTitle: "DM Definition",
        importance: "high",
        backContent: [
            "ğŸ” DEFINITION: Discovery of hidden patterns from large datasets.",
            "ğŸ¯ GOAL: Extract useful knowledge for decision making.",
            "ğŸ“Š ALSO CALLED: Knowledge Discovery in Databases (KDD).",
            "âš¡ MOTIVATION:",
            "  â€¢ Business intelligence",
            "  â€¢ Fraud detection",
            "  â€¢ Customer segmentation",
            "  â€¢ Recommendation systems",
            "âš¡ AKTU: Define data mining with applications"
        ]
    },
    {
        id: 2,
        title: "2. Data Mining Functionalities",
        frontText: "What can DM do?",
        backTitle: "DM Tasks",
        importance: "high",
        backContent: [
            "ğŸ“Š CLASSIFICATION: Assign class labels (Spam/Not Spam).",
            "ğŸ”— CLUSTERING: Group similar objects (Customer segments).",
            "ğŸ›’ ASSOCIATION: Find item relationships (Market basket).",
            "ğŸ“ˆ PREDICTION: Forecast future values (Stock prices).",
            "ğŸ” OUTLIER ANALYSIS: Detect anomalies (Fraud).",
            "ğŸ“‰ REGRESSION: Predict numeric values.",
            "âš¡ AKTU: List 5 DM functionalities with examples"
        ]
    },
    {
        id: 3,
        title: "3. Data Pre-Processing Overview",
        frontText: "Why preprocess data?",
        backTitle: "Pre-Processing Need",
        importance: "high",
        backContent: [
            "âš ï¸ RAW DATA IS: Incomplete, noisy, inconsistent.",
            "ğŸ¯ GOAL: Improve data quality for better mining results.",
            "ğŸ“‹ STEPS:",
            "  â€¢ Data Cleaning",
            "  â€¢ Data Integration",
            "  â€¢ Data Transformation",
            "  â€¢ Data Reduction",
            "âš¡ AKTU Very Important: Explain why preprocessing is needed"
        ]
    },
    {
        id: 4,
        title: "4. Data Cleaning - Missing Values",
        frontText: "Handling incomplete data",
        backTitle: "Missing Value Methods",
        importance: "high",
        backContent: [
            "â“ MISSING VALUES: Empty cells in dataset.",
            "ğŸ”§ METHODS TO HANDLE:",
            "  â€¢ Ignore tuple (if many missing)",
            "  â€¢ Fill manually (expensive)",
            "  â€¢ Use global constant (e.g., 'Unknown')",
            "  â€¢ Use MEAN/MEDIAN of attribute",
            "  â€¢ Use REGRESSION to predict value",
            "  â€¢ Use most probable value (Bayesian)",
            "âš¡ AKTU: List methods to handle missing values"
        ]
    },
    {
        id: 5,
        title: "5. Data Cleaning - Noisy Data",
        frontText: "Handling errors & outliers",
        frontImage: "/dwm/binning_techniques.png",
        backTitle: "Noise Smoothing Techniques",
        importance: "high",
        backContent: [
            "ğŸ“Š NOISY DATA: Random errors, outliers.",
            "ğŸ”§ SMOOTHING TECHNIQUES:",
            "  â€¢ BINNING: Sort and smooth by bin (mean/median/boundaries)",
            "  â€¢ CLUSTERING: Group similar, detect outliers",
            "  â€¢ REGRESSION: Fit data to function",
            "  â€¢ HUMAN INSPECTION: Manual review",
            "âš¡ AKTU Very Important: Explain binning with example"
        ]
    },
    {
        id: 6,
        title: "6. Data Integration & Transformation",
        frontText: "Combining and converting data",
        backTitle: "Integration & Transform",
        importance: "medium",
        backContent: [
            "ğŸ”— DATA INTEGRATION: Combine multiple sources.",
            "  â€¢ Schema integration (match attributes)",
            "  â€¢ Entity identification (match records)",
            "  â€¢ Redundancy detection",
            "ğŸ”„ DATA TRANSFORMATION:",
            "  â€¢ NORMALIZATION: Scale to [0,1] or [-1,1]",
            "  â€¢ AGGREGATION: Summarize (daily â†’ monthly)",
            "  â€¢ GENERALIZATION: Low-level â†’ High-level (age â†’ age-group)",
            "âš¡ AKTU: Explain normalization formulas"
        ]
    },
    {
        id: 7,
        title: "7. Data Reduction - Cube Aggregation",
        frontText: "Reducing data volume",
        backTitle: "Reduction Techniques",
        importance: "high",
        backContent: [
            "ğŸ¯ GOAL: Reduce size while maintaining integrity.",
            "ğŸ§Š DATA CUBE AGGREGATION: Pre-compute aggregates.",
            "ğŸ“‰ DIMENSIONALITY REDUCTION: Reduce attributes (PCA).",
            "ğŸ—œï¸ DATA COMPRESSION: Lossless or lossy.",
            "ğŸ”¢ NUMEROSITY REDUCTION: Replace with models (regression).",
            "âš¡ AKTU: Explain data cube aggregation"
        ]
    },
    {
        id: 8,
        title: "8. Discretization & Concept Hierarchy",
        frontText: "Converting continuous to categorical",
        backTitle: "Discretization",
        importance: "medium",
        backContent: [
            "ğŸ“Š DISCRETIZATION: Divide continuous range into intervals.",
            "  â€¢ Age: 0-18 (Youth), 19-35 (Adult), 36+ (Senior)",
            "ğŸ”¼ CONCEPT HIERARCHY: Generalization levels.",
            "  â€¢ City â†’ State â†’ Country â†’ Continent",
            "ğŸ¯ BENEFITS: Simplifies data, reduces noise.",
            "âš¡ AKTU: Define concept hierarchy with example"
        ]
    },
    {
        id: 9,
        title: "9. Decision Tree Introduction",
        frontText: "Tree-based classification",
        frontImage: "/dwm/decision_tree.png",
        backTitle: "Decision Tree Basics",
        importance: "high",
        backContent: [
            "ğŸŒ³ DECISION TREE: Flowchart-like structure.",
            "ğŸ”¹ INTERNAL NODES: Test on attribute.",
            "ğŸ”¹ BRANCHES: Outcome of test.",
            "ğŸ”¹ LEAF NODES: Class label (decision).",
            "ğŸ“Š ALGORITHMS: ID3, C4.5, CART.",
            "ğŸ¯ ATTRIBUTE SELECTION:",
            "  â€¢ Information Gain (ID3)",
            "  â€¢ Gain Ratio (C4.5)",
            "  â€¢ Gini Index (CART)",
            "âš¡ AKTU Very Important: Draw decision tree, explain Info Gain"
        ]
    }
];
