import { type FlashcardData } from '../components/Flashcard';

export const dlUnit5Data: FlashcardData[] = [
    {
        id: 1,
        title: "1. ImageNet & Large-Scale Visual Recognition",
        frontText: "The Dataset That Started the Revolution",
        backTitle: "ImageNet Details",
        importance: "high",
        backContent: [
            "üìä IMAGENET DATABASE:",
            "  ‚Ä¢ 14+ million images, 20,000+ categories",
            "  ‚Ä¢ ImageNet Large Scale Visual Recognition Challenge (ILSVRC)",
            "  ‚Ä¢ 1000 classes subset for competition",
            "üèÜ MILESTONES:",
            "  ‚Ä¢ 2012: AlexNet (15.3% error) - Deep learning begins",
            "  ‚Ä¢ 2014: VGGNet (7.3%), GoogLeNet (6.7%)",
            "  ‚Ä¢ 2015: ResNet (3.6%) - Surpassed human level!",
            "  ‚Ä¢ Human error: ~5%",
            "üìà IMPACT:",
            "  ‚Ä¢ Standardized benchmark for computer vision",
            "  ‚Ä¢ Enabled transfer learning (pretrained models)",
            "‚ö° AKTU: ImageNet significance, accuracy progression"
        ]
    },
    {
        id: 2,
        title: "2. Object Detection",
        frontText: "Localizing and Classifying Objects",
        backTitle: "Detection Methods",
        importance: "high",
        backContent: [
            "üéØ TASK: WHERE is object + WHAT is it (bounding box + class)",
            "üìä TWO-STAGE DETECTORS:",
            "  ‚Ä¢ R-CNN: Region proposals ‚Üí CNN ‚Üí Classify each",
            "  ‚Ä¢ Fast R-CNN: Shared CNN features, ROI pooling",
            "  ‚Ä¢ Faster R-CNN: Region Proposal Network (RPN) - end-to-end",
            "‚ö° ONE-STAGE DETECTORS:",
            "  ‚Ä¢ YOLO: Divide image into grid, predict boxes directly",
            "  ‚Ä¢ SSD: Multi-scale detection, various anchor boxes",
            "üìê METRICS:",
            "  ‚Ä¢ IoU (Intersection over Union) = Area(‚à©)/Area(‚à™)",
            "  ‚Ä¢ mAP (mean Average Precision)",
            "‚úÖ APPLICATIONS: Autonomous driving, surveillance, robotics",
            "‚ö° AKTU Important: R-CNN vs YOLO, IoU calculation"
        ]
    },
    {
        id: 3,
        title: "3. WaveNet for Audio",
        frontText: "Generative Model for Raw Audio",
        backTitle: "WaveNet Architecture",
        importance: "medium",
        backContent: [
            "üéµ TASK: Generate realistic speech waveforms",
            "üèóÔ∏è ARCHITECTURE:",
            "  ‚Ä¢ Autoregressive: P(x) = Œ† P(x‚Çú|x‚ÇÅ,...,x‚Çú‚Çã‚ÇÅ)",
            "  ‚Ä¢ Dilated causal convolutions (exponentially increasing dilation)",
            "  ‚Ä¢ Gated activation units",
            "üìê DILATED CONVOLUTIONS:",
            "  ‚Ä¢ Dilation = 1, 2, 4, 8, 16, 32, ...",
            "  ‚Ä¢ Large receptive field with few layers",
            "  ‚Ä¢ Causal: Can only see past (not future)",
            "‚úÖ APPLICATIONS:",
            "  ‚Ä¢ Text-to-Speech (Google, DeepMind)",
            "  ‚Ä¢ Music generation",
            "  ‚Ä¢ Voice conversion",
            "‚ö° AKTU: Dilated convolutions, autoregressive model"
        ]
    },
    {
        id: 4,
        title: "4. NLP and Word2Vec Applications",
        frontText: "Natural Language Processing with Deep Learning",
        backTitle: "NLP Applications",
        importance: "high",
        backContent: [
            "üìù NLP TASKS:",
            "  ‚Ä¢ Text Classification: Sentiment, Spam detection",
            "  ‚Ä¢ Named Entity Recognition (NER): Extract entities",
            "  ‚Ä¢ Machine Translation: Seq2Seq with attention",
            "  ‚Ä¢ Question Answering: Reading comprehension",
            "üî§ WORD2VEC APPLICATIONS:",
            "  ‚Ä¢ Word similarity: cosine(v‚ÇÅ, v‚ÇÇ)",
            "  ‚Ä¢ Word analogies: king - man + woman = queen",
            "  ‚Ä¢ Document classification: Average word vectors",
            "üìä MODERN MODELS:",
            "  ‚Ä¢ ELMo: Contextual embeddings",
            "  ‚Ä¢ BERT: Bidirectional, pretrain + finetune",
            "  ‚Ä¢ GPT: Generative, autoregressive",
            "‚ö° AKTU: Word2Vec applications, BERT vs GPT"
        ]
    },
    {
        id: 5,
        title: "5. Joint Detection & Multi-Task Learning",
        frontText: "Solving Multiple Tasks Together",
        backTitle: "Multi-Task Approaches",
        importance: "medium",
        backContent: [
            "üéØ IDEA: Share representations across related tasks",
            "üìä EXAMPLES:",
            "  ‚Ä¢ Object Detection + Segmentation (Mask R-CNN)",
            "  ‚Ä¢ Pose Estimation + Action Recognition",
            "  ‚Ä¢ Language Translation + Language Modeling",
            "‚úÖ BENEFITS:",
            "  ‚Ä¢ Improved generalization (regularization effect)",
            "  ‚Ä¢ Efficient computation (shared features)",
            "  ‚Ä¢ Less data needed per task",
            "üèóÔ∏è ARCHITECTURE:",
            "  ‚Ä¢ Shared encoder/backbone",
            "  ‚Ä¢ Task-specific heads/decoders",
            "  ‚Ä¢ Multi-task loss: L = Œ£Œª·µ¢¬∑L·µ¢",
            "‚ö° AKTU: Multi-task learning benefits, architecture design"
        ]
    },
    {
        id: 6,
        title: "6. Bioinformatics Applications",
        frontText: "Deep Learning in Biology & Medicine",
        backTitle: "Bio Applications",
        importance: "medium",
        backContent: [
            "üß¨ GENOMICS:",
            "  ‚Ä¢ DNA sequence analysis: CNNs on sequences",
            "  ‚Ä¢ Gene expression prediction",
            "  ‚Ä¢ Mutation effect prediction",
            "üíä DRUG DISCOVERY:",
            "  ‚Ä¢ Molecular property prediction (Graph NNs)",
            "  ‚Ä¢ Drug-target interaction",
            "  ‚Ä¢ Protein structure prediction (AlphaFold!)",
            "üè• MEDICAL IMAGING:",
            "  ‚Ä¢ Tumor detection (CT, MRI, X-ray)",
            "  ‚Ä¢ Diabetic retinopathy screening",
            "  ‚Ä¢ Pathology slide analysis",
            "üìä ALPHAFOLD (2020): Solved 50-year protein folding problem!",
            "‚ö° AKTU: Applications in medical imaging, AlphaFold significance"
        ]
    },
    {
        id: 7,
        title: "7. Face Recognition",
        frontText: "Identity Verification with Deep Learning",
        backTitle: "Face Recognition Pipeline",
        importance: "high",
        backContent: [
            "üéØ TASKS:",
            "  ‚Ä¢ Face Detection: Where is the face?",
            "  ‚Ä¢ Face Alignment: Normalize position/orientation",
            "  ‚Ä¢ Face Verification: Are these the same person?",
            "  ‚Ä¢ Face Identification: Who is this person?",
            "üèóÔ∏è ARCHITECTURES:",
            "  ‚Ä¢ DeepFace (Facebook 2014): 97.35% on LFW",
            "  ‚Ä¢ FaceNet (Google 2015): Triplet loss, 128-D embeddings",
            "  ‚Ä¢ ArcFace: Additive angular margin loss",
            "üìê TRIPLET LOSS:",
            "  d(anchor, positive) + margin < d(anchor, negative)",
            "üìä BENCHMARKS: LFW (Labeled Faces in Wild), MegaFace",
            "‚ö° AKTU Important: Face recognition pipeline, FaceNet"
        ]
    },
    {
        id: 8,
        title: "8. Scene Understanding",
        frontText: "Comprehensive Visual Understanding",
        backTitle: "Scene Analysis Tasks",
        importance: "medium",
        backContent: [
            "üñºÔ∏è RELATED TASKS:",
            "  ‚Ä¢ CLASSIFICATION: What's in the image?",
            "  ‚Ä¢ DETECTION: Where are objects?",
            "  ‚Ä¢ SEGMENTATION: Pixel-level labeling",
            "  ‚Ä¢ DEPTH ESTIMATION: How far is everything?",
            "üìä SEMANTIC SEGMENTATION:",
            "  ‚Ä¢ FCN (Fully Convolutional Networks)",
            "  ‚Ä¢ U-Net: Encoder-decoder with skip connections",
            "  ‚Ä¢ DeepLab: Atrous/dilated convolutions",
            "üé≠ INSTANCE SEGMENTATION:",
            "  ‚Ä¢ Separate masks for each object instance",
            "  ‚Ä¢ Mask R-CNN: Detection + Segmentation",
            "‚úÖ APPLICATIONS: Autonomous driving, AR/VR, Robotics",
            "‚ö° AKTU: Semantic vs Instance segmentation, FCN vs U-Net"
        ]
    },
    {
        id: 9,
        title: "9. Image Captioning",
        frontText: "Generating Text from Images",
        backTitle: "Captioning Methods",
        importance: "high",
        backContent: [
            "üéØ TASK: Generate natural language description of image",
            "üèóÔ∏è ENCODER-DECODER ARCHITECTURE:",
            "  ‚Ä¢ ENCODER: CNN (VGG/ResNet) ‚Üí Image features",
            "  ‚Ä¢ DECODER: RNN/LSTM ‚Üí Generate words sequentially",
            "üîç ATTENTION MECHANISM:",
            "  ‚Ä¢ Focus on relevant image regions for each word",
            "  ‚Ä¢ 'Show, Attend and Tell' (2015)",
            "  ‚Ä¢ Soft attention: Weighted average of all regions",
            "  ‚Ä¢ Hard attention: Select one region (non-differentiable)",
            "üìä MODERN: Transformers for both vision and text",
            "üìê METRICS: BLEU, METEOR, CIDEr, SPICE",
            "‚úÖ APPLICATIONS: Accessibility, Image search, Content moderation",
            "‚ö° AKTU Important: Encoder-decoder, attention in captioning"
        ]
    },
    {
        id: 10,
        title: "10. Summary: AKTU Exam Focus Areas",
        frontText: "Most Important Topics for Exam",
        backTitle: "High-Priority Topics",
        importance: "high",
        backContent: [
            "üî¥ UNIT 1: Perceptron, Backpropagation, SGD, Loss Functions",
            "üî¥ UNIT 2: CNN architecture, Batch Normalization, GANs, Deep vs Shallow",
            "üî¥ UNIT 3: PCA/LDA derivation, AlexNet/VGG/ResNet, Autoencoders",
            "üî¥ UNIT 4: LSTM gates, Word2Vec, Adam optimizer, RNN types",
            "üî¥ UNIT 5: ImageNet history, Object Detection (YOLO/RCNN), Face Recognition",
            "üìù COMMONLY ASKED:",
            "  ‚Ä¢ Compare questions (PCA vs LDA, CNN vs RNN, Adam vs SGD)",
            "  ‚Ä¢ Derive equations (backprop, LSTM gates, batch norm)",
            "  ‚Ä¢ Architecture diagrams (CNN, LSTM, GAN)",
            "  ‚Ä¢ Applications and case studies",
            "‚ö° TIP: Practice previous year questions, focus on derivations!"
        ]
    }
];
