import { type FlashcardData } from '../components/Flashcard';

export const dlUnit3Data: FlashcardData[] = [
    {
        id: 1,
        title: "1. Principal Component Analysis (PCA)",
        frontText: "Linear Dimensionality Reduction",
        backTitle: "PCA Algorithm",
        importance: "high",
        backContent: [
            "üéØ GOAL: Reduce dimensions while preserving maximum variance",
            "üìê ALGORITHM:",
            "  1. Center data: XÃÑ = X - mean(X)",
            "  2. Compute covariance matrix: C = (1/n)XÃÑ·µÄXÃÑ",
            "  3. Find eigenvalues Œª‚ÇÅ ‚â• Œª‚ÇÇ ‚â• ... and eigenvectors",
            "  4. Select top k eigenvectors as principal components",
            "  5. Project: Z = XÃÑ ¬∑ W‚Çñ",
            "üìä VARIANCE EXPLAINED: Œ£·µ¢‚Çå‚ÇÅ·µè Œª·µ¢ / Œ£‚±º Œª‚±º",
            "‚úÖ APPLICATIONS: Face recognition, Data visualization, Noise reduction",
            "‚ö†Ô∏è LIMITATION: Only captures LINEAR relationships",
            "‚ö° AKTU VERY IMPORTANT: PCA algorithm, variance explained, example"
        ]
    },
    {
        id: 2,
        title: "2. Linear Discriminant Analysis (LDA)",
        frontText: "Supervised Dimensionality Reduction",
        backTitle: "LDA Details",
        importance: "high",
        backContent: [
            "üéØ GOAL: Maximize class separability while reducing dimensions",
            "üÜö PCA vs LDA:",
            "  ‚Ä¢ PCA: Unsupervised, maximizes variance",
            "  ‚Ä¢ LDA: Supervised, maximizes class separation",
            "üìê OBJECTIVE: Maximize (Between-class scatter) / (Within-class scatter)",
            "  ‚Ä¢ S·µ¶ = Œ£n‚Çñ(Œº‚Çñ - Œº)(Œº‚Çñ - Œº)·µÄ (between-class)",
            "  ‚Ä¢ S·µ• = Œ£Œ£(x - Œº‚Çñ)(x - Œº‚Çñ)·µÄ (within-class)",
            "  ‚Ä¢ Maximize: J(w) = w·µÄS·µ¶w / w·µÄS·µ•w",
            "üìä MAX COMPONENTS: min(classes-1, features)",
            "‚ö° AKTU Important: Compare PCA vs LDA, Fisher's criterion"
        ]
    },
    {
        id: 3,
        title: "3. Manifold Learning",
        frontText: "Non-Linear Dimensionality Reduction",
        backTitle: "Manifold Methods",
        importance: "medium",
        backContent: [
            "üéØ ASSUMPTION: High-D data lies on low-D manifold (curved surface)",
            "üìä METHODS:",
            "  ‚Ä¢ ISOMAP: Preserve geodesic distances (shortest path on manifold)",
            "  ‚Ä¢ LLE (Locally Linear Embedding): Preserve local linear structure",
            "  ‚Ä¢ t-SNE: Preserve local similarities (great for visualization)",
            "  ‚Ä¢ UMAP: t-SNE alternative, faster, preserves global structure better",
            "üìà t-SNE DETAILS:",
            "  ‚Ä¢ Convert distances to probabilities",
            "  ‚Ä¢ Minimize KL divergence between high-D and low-D probabilities",
            "  ‚Ä¢ Non-parametric (can't embed new points directly)",
            "‚ö° AKTU: Explain manifold hypothesis, compare t-SNE vs PCA"
        ]
    },
    {
        id: 4,
        title: "4. Metric Learning",
        frontText: "Learning Distance Functions",
        backTitle: "Metric Learning Methods",
        importance: "medium",
        backContent: [
            "üéØ GOAL: Learn distance function where similar items are closer",
            "üìê MAHALANOBIS DISTANCE: d(x,y) = ‚àö((x-y)·µÄM(x-y))",
            "  ‚Ä¢ M = positive semi-definite matrix (learned)",
            "üîß METHODS:",
            "  ‚Ä¢ LMNN (Large Margin Nearest Neighbor): k-NN with margin",
            "  ‚Ä¢ NCA (Neighbourhood Component Analysis): Softmax-based",
            "  ‚Ä¢ TRIPLET LOSS: d(anchor, positive) < d(anchor, negative) + margin",
            "üìä TRIPLET MINING:",
            "  ‚Ä¢ Hard: Most difficult triplets",
            "  ‚Ä¢ Semi-hard: Violate margin but not order",
            "‚úÖ APPLICATIONS: Face verification, Image retrieval, One-shot learning",
            "‚ö° AKTU: Triplet loss formula, Siamese networks"
        ]
    },
    {
        id: 5,
        title: "5. Autoencoders",
        frontText: "Unsupervised Feature Learning",
        backTitle: "Autoencoder Types",
        importance: "high",
        backContent: [
            "üèóÔ∏è ARCHITECTURE: Input ‚Üí Encoder ‚Üí Bottleneck ‚Üí Decoder ‚Üí Output",
            "üéØ OBJECTIVE: Reconstruct input, minimize ||x - xÃÇ||¬≤",
            "üìä TYPES:",
            "  ‚Ä¢ VANILLA: Simple encoder-decoder",
            "  ‚Ä¢ SPARSE: Add L1 penalty on activations (force sparsity)",
            "  ‚Ä¢ DENOISING: Add noise to input, reconstruct clean output",
            "  ‚Ä¢ VARIATIONAL (VAE): Learn latent distribution z ~ N(Œº, œÉ¬≤)",
            "üìê VAE LOSS: Reconstruction + KL divergence (regularization)",
            "  L = ||x - xÃÇ||¬≤ + KL(q(z|x) || p(z))",
            "‚úÖ APPLICATIONS: Dimensionality reduction, Anomaly detection, Generation",
            "‚ö° AKTU Important: Autoencoder architecture, VAE loss function"
        ]
    },
    {
        id: 6,
        title: "6. ConvNet Introduction",
        frontText: "Building Blocks of CNNs",
        backTitle: "CNN Components",
        importance: "high",
        backContent: [
            "üìê CONVOLUTION OPERATION:",
            "  ‚Ä¢ Filter (kernel) slides across input",
            "  ‚Ä¢ Output(i,j) = Œ£‚Çò,‚Çô Input(i+m, j+n) √ó Filter(m,n)",
            "üîß HYPERPARAMETERS:",
            "  ‚Ä¢ Kernel Size: 3√ó3, 5√ó5, 7√ó7 (odd numbers)",
            "  ‚Ä¢ Stride: Step size (1 = every pixel, 2 = skip)",
            "  ‚Ä¢ Padding: 'same' (keep size) or 'valid' (shrink)",
            "üìä OUTPUT SIZE: (N - F + 2P)/S + 1",
            "üèä POOLING:",
            "  ‚Ä¢ Max Pooling: Take max in each window (most common)",
            "  ‚Ä¢ Average Pooling: Take average",
            "  ‚Ä¢ Global Pooling: Reduce entire feature map to 1 value",
            "‚ö° AKTU: Convolution formula, output size calculation, pooling types"
        ]
    },
    {
        id: 7,
        title: "7. AlexNet (2012)",
        frontText: "ImageNet Breakthrough",
        backTitle: "AlexNet Architecture",
        importance: "high",
        backContent: [
            "üèÜ ACHIEVEMENT: Won ImageNet 2012, 15.3% error (vs 26.2% 2nd place)",
            "üèóÔ∏è ARCHITECTURE: 5 Conv + 3 FC layers, 60M parameters",
            "  ‚Ä¢ Input: 227√ó227√ó3",
            "  ‚Ä¢ Conv layers: 96‚Üí256‚Üí384‚Üí384‚Üí256 filters",
            "‚öôÔ∏è KEY INNOVATIONS:",
            "  ‚Ä¢ ReLU activation (faster than tanh/sigmoid)",
            "  ‚Ä¢ Dropout (p=0.5) in FC layers",
            "  ‚Ä¢ Data augmentation (crops, flips, color jitter)",
            "  ‚Ä¢ Local Response Normalization (later replaced by BatchNorm)",
            "  ‚Ä¢ GPU training (2 GPUs)",
            "üìä Started modern deep learning revolution",
            "‚ö° AKTU Important: AlexNet innovations, architecture diagram"
        ]
    },
    {
        id: 8,
        title: "8. VGG, Inception, ResNet",
        frontText: "Landmark CNN Architectures",
        backTitle: "Architecture Evolution",
        importance: "high",
        backContent: [
            "üî∑ VGG-16/19 (2014):",
            "  ‚Ä¢ All 3√ó3 conv, very deep (16-19 layers)",
            "  ‚Ä¢ Simple, uniform architecture ‚Üí 138M params",
            "üî∂ INCEPTION/GoogLeNet (2014):",
            "  ‚Ä¢ Inception modules: Parallel 1√ó1, 3√ó3, 5√ó5 convs",
            "  ‚Ä¢ 22 layers, only 5M parameters (efficient)",
            "  ‚Ä¢ 1√ó1 convs for dimensionality reduction",
            "üî¥ RESNET (2015):",
            "  ‚Ä¢ Skip/Residual connections: y = F(x) + x",
            "  ‚Ä¢ Solves vanishing gradient, enables 100+ layers",
            "  ‚Ä¢ ResNet-50, ResNet-101, ResNet-152",
            "‚ö° AKTU VERY IMPORTANT: Compare architectures, skip connections"
        ]
    },
    {
        id: 9,
        title: "9. Weight Initialization & Hyperparameters",
        frontText: "Getting Training Right",
        backTitle: "Initialization & Tuning",
        importance: "high",
        backContent: [
            "‚ö†Ô∏è BAD INIT: All zeros ‚Üí all neurons same, no learning",
            "üìê INITIALIZATION METHODS:",
            "  ‚Ä¢ Xavier/Glorot: w ~ N(0, 2/(n·µ¢‚Çô + n‚Çí·µ§‚Çú)) - for sigmoid/tanh",
            "  ‚Ä¢ He/Kaiming: w ~ N(0, 2/n·µ¢‚Çô) - for ReLU",
            "üîß HYPERPARAMETERS TO TUNE:",
            "  ‚Ä¢ Learning rate: Start 1e-3, use LR schedulers",
            "  ‚Ä¢ Batch size: 32-256 typical",
            "  ‚Ä¢ Number of layers, neurons per layer",
            "  ‚Ä¢ Dropout rate, regularization strength",
            "üîç TUNING METHODS:",
            "  ‚Ä¢ Grid Search, Random Search",
            "  ‚Ä¢ Bayesian Optimization, Learning rate finder",
            "‚ö° AKTU: Xavier vs He init derivation, hyperparameter impact"
        ]
    }
];
